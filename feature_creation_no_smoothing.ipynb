{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 218,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import numpy as np\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 219,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                       O3_ppb    UnixTime       e2v03       Temp         Rh  \\\n",
      "DATE (MM/DD/YYYY)_MST                                                         \n",
      "7/10/14 20:25              41  1405023930  114.714286  45.800000  11.400000   \n",
      "7/10/14 20:26              39  1405023991  120.428571  45.814286  11.314286   \n",
      "7/10/14 20:27              44  1405024053  119.142857  45.857143  11.300000   \n",
      "7/10/14 20:28              47  1405024110  117.500000  45.900000  11.300000   \n",
      "7/10/14 20:29              44  1405024167  120.285714  45.900000  11.457143   \n",
      "\n",
      "                       Zenith Angle [degrees]  days from start  ref_o3_smooth  \\\n",
      "DATE (MM/DD/YYYY)_MST                                                           \n",
      "7/10/14 20:25                        99.48960                0             41   \n",
      "7/10/14 20:26                        99.63789                0             39   \n",
      "7/10/14 20:27                        99.78580                0             44   \n",
      "7/10/14 20:28                        99.93332                0             47   \n",
      "7/10/14 20:29                       100.08045                0             44   \n",
      "\n",
      "                       pod_o3_smooth  \n",
      "DATE (MM/DD/YYYY)_MST                 \n",
      "7/10/14 20:25             114.714286  \n",
      "7/10/14 20:26             120.428571  \n",
      "7/10/14 20:27             119.142857  \n",
      "7/10/14 20:28             117.500000  \n",
      "7/10/14 20:29             120.285714  \n"
     ]
    }
   ],
   "source": [
    "df_P = pd.io.parsers.read_csv(filepath_or_buffer = 'data/D0_filt_10mino3.csv',index_col = 0)\n",
    "print df_P[:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 220,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                       O3_ppb    UnixTime       e2v03       Temp         Rh  \\\n",
      "DATE (MM/DD/YYYY)_MST                                                         \n",
      "7/10/14 20:25              41  1405023930  114.714286  45.800000  11.400000   \n",
      "7/10/14 20:26              39  1405023991  120.428571  45.814286  11.314286   \n",
      "7/10/14 20:27              44  1405024053  119.142857  45.857143  11.300000   \n",
      "7/10/14 20:28              47  1405024110  117.500000  45.900000  11.300000   \n",
      "7/10/14 20:29              44  1405024167  120.285714  45.900000  11.457143   \n",
      "\n",
      "                       Zenith Angle [degrees]  days from start  \n",
      "DATE (MM/DD/YYYY)_MST                                           \n",
      "7/10/14 20:25                        99.48960                0  \n",
      "7/10/14 20:26                        99.63789                0  \n",
      "7/10/14 20:27                        99.78580                0  \n",
      "7/10/14 20:28                        99.93332                0  \n",
      "7/10/14 20:29                       100.08045                0  \n"
     ]
    }
   ],
   "source": [
    "df_P.drop(df_P.columns[[7,8]], axis=1, inplace=True)\n",
    "print df_P[:5]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "####Define the slope function."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 221,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def find_lag_slope(df_P, int_min, data_col):\n",
    "    df_P['diff'] = df_P[data_col].diff()\n",
    "    \n",
    "    slope = []\n",
    "    for i in range(int_min,len(df_P['diff'])):\n",
    "        top = i-int_min\n",
    "        slope.append(df_P['diff'][top:i].mean())\n",
    "    \n",
    "    for i in range(0,int_min):\n",
    "        slope.insert(i, 'NaN')\n",
    "\n",
    "    return slope"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 222,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def find_lead_slope(df_P, int_min, data_col):\n",
    "    df_P['diff'] = df_P[data_col].diff()\n",
    "    slope = []\n",
    "    for i in range(0,len(df_P[data_col])-int_min):\n",
    "        top = i + int_min\n",
    "        slope.append(df_P['diff'][i:top].mean())\n",
    "    \n",
    "    for i in range(len(df_P[data_col])-int_min, len(df_P[data_col])):\n",
    "        slope.insert(i, 'NaN')\n",
    "\n",
    "    return slope"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "####Define functions that create features that represent the area under the temp and humidity curves."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 223,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def find_lag_integral(df_P, int_min, data_col):\n",
    "    area_curve = []\n",
    "\n",
    "    for i in range(int_min,len(df_P[data_col])):\n",
    "        top = i - int_min\n",
    "        area_curve.append(np.trapz(df_P[data_col][top:i]))\n",
    "    \n",
    "    for i in range(0,int_min):\n",
    "        area_curve.insert(i, 'NaN')\n",
    "    \n",
    "    return area_curve"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 224,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def find_lead_integral(df_P, int_min, data_col):\n",
    "    area_curve = []\n",
    "\n",
    "    for i in range(0,len(df_P[data_col])-int_min):\n",
    "        top = i + int_min\n",
    "        area_curve.append(np.trapz(df_P[data_col][i:top]))\n",
    "    \n",
    "    for i in range(len(df_P[data_col])-int_min, len(df_P[data_col])):\n",
    "        area_curve.insert(i, 'NaN')\n",
    "    \n",
    "    return area_curve"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 225,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#relative start time must be less than relative end time\n",
    "def sliding_integral_lag(df_P, start_min_before, end_min_before, column):\n",
    "    interval = start_min_before - end_min_before \n",
    "    a = df_P['e2v03'].shift(end_min_before).values\n",
    "    v = np.zeros(interval)\n",
    "    v[0:interval] = 1\n",
    "    out = np.convolve(a, v, 'valid')\n",
    "    out = np.concatenate((np.array([float('nan')] * (interval-1)), out))\n",
    "    return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 363,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#relative start time must be less than relative end time\n",
    "def sliding_integral_lead(df_P, start_min_after, end_min_after, column):\n",
    "    interval = end_min_after - start_min_after \n",
    "    a = df_P[column].shift(start_min_after).values\n",
    "    a = a[~np.isnan(a)]\n",
    "    v = np.zeros(end_min_after)\n",
    "    v[0:interval] = 1\n",
    "    out = np.convolve(a, v, 'valid')\n",
    "    out = np.concatenate((out, np.array([float('nan')] * (start_min_after+end_min_after-1))))\n",
    "    return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 368,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ 0  1  2  3  4  5  6  7  8  9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24\n",
      " 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44]\n",
      "[ 110.   nan   nan   nan   nan   nan   nan   nan   nan   nan   nan   nan\n",
      "   nan   nan   nan   nan   nan   nan   nan   nan   nan   nan   nan   nan\n",
      "   nan   nan   nan   nan   nan   nan   nan   nan   nan   nan   nan   nan\n",
      "   nan   nan   nan   nan   nan   nan   nan   nan   nan]\n",
      "45\n"
     ]
    }
   ],
   "source": [
    "a = np.arange(0,45)\n",
    "print a\n",
    "a = pd.DataFrame({'a':a})\n",
    "\n",
    "df_new = sliding_integral_lead(a, 20, 25, 'a')\n",
    "print df_new\n",
    "print len(df_new)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 325,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ 0  1  2  3  4  5  6  7  8  9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24]\n",
      "out:  [  10.   15.   20.   25.   30.   35.   40.   45.   50.   55.   60.   65.\n",
      "   70.   75.   80.   85.   90.   95.  100.  105.  110.   nan   nan   nan\n",
      "   nan]\n",
      "25\n"
     ]
    }
   ],
   "source": [
    "#0-5 minutes after, i = 5\n",
    "#a = df_P['e2v03'].shift(5)[:25].values\n",
    "a = np.arange(0,25)\n",
    "print a\n",
    "a = pd.DataFrame({'a':a}).shift(0).values\n",
    "a = np.transpose(a)\n",
    "a = a[~np.isnan(a)]\n",
    "v = np.zeros(5)\n",
    "v[0:5] = 1\n",
    "out = np.convolve(a, v, 'valid')\n",
    "out = np.concatenate((out, np.array([float('nan')] * (5-1))))\n",
    "print 'out: ', out\n",
    "print len(out)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 321,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ 0  1  2  3  4  5  6  7  8  9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24]\n",
      "out:  [ 35.  40.  45.  50.  55.  60.  65.  70.  75.  80.  85.  nan  nan  nan  nan\n",
      "  nan  nan  nan  nan  nan  nan  nan  nan  nan  nan]\n",
      "25\n"
     ]
    }
   ],
   "source": [
    "#5-10 minutes after, i = 5\n",
    "#a = df_P['e2v03'].shift(5)[:25].values\n",
    "a = np.arange(0,25)\n",
    "print a\n",
    "a = pd.DataFrame({'a':a}).shift(5).values\n",
    "a = np.transpose(a)\n",
    "a = a[~np.isnan(a)]\n",
    "v = np.zeros(10)\n",
    "v[0:5] = 1\n",
    "out = np.convolve(a, v, 'valid')\n",
    "out = np.concatenate((out, np.array([float('nan')] * (10+5-1))))\n",
    "print 'out: ', out\n",
    "print len(out)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 330,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ 0  1  2  3  4  5  6  7  8  9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24\n",
      " 25 26 27 28 29]\n",
      "out:  [ 60.  65.  70.  75.  80.  85.  nan  nan  nan  nan  nan  nan  nan  nan  nan\n",
      "  nan  nan  nan  nan  nan  nan  nan  nan  nan  nan  nan  nan  nan  nan  nan]\n",
      "30\n"
     ]
    }
   ],
   "source": [
    "#10-15 minutes after, i = 5\n",
    "#a = df_P['e2v03'].shift(5)[:25].values\n",
    "a = np.arange(0,30)\n",
    "print a\n",
    "a = pd.DataFrame({'a':a}).shift(10).values\n",
    "a = np.transpose(a)\n",
    "a = a[~np.isnan(a)]\n",
    "v = np.zeros(15)\n",
    "v[0:5] = 1\n",
    "out = np.convolve(a, v, 'valid')\n",
    "out = np.concatenate((out, np.array([float('nan')] * (10+15-1))))\n",
    "print 'out: ', out\n",
    "print len(out)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 327,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ 0  1  2  3  4  5  6  7  8  9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24]\n",
      "out:  [  45.   55.   65.   75.   85.   95.  105.  115.  125.  135.  145.  155.\n",
      "  165.  175.  185.  195.   nan   nan   nan   nan   nan   nan   nan   nan\n",
      "   nan]\n",
      "25\n",
      "25\n"
     ]
    }
   ],
   "source": [
    "#0-10 minutes after, i = 5\n",
    "#a = df_P['e2v03'].shift(5)[:25].values\n",
    "a = np.arange(0,25)\n",
    "print a\n",
    "a = pd.DataFrame({'a':a}).shift(0).values\n",
    "a = np.transpose(a)\n",
    "a = a[~np.isnan(a)]\n",
    "v = np.zeros(10)\n",
    "v[0:10] = 1\n",
    "out = np.convolve(a, v, 'valid')\n",
    "out = np.concatenate((out, np.array([float('nan')] * (10-1))))\n",
    "print 'out: ', out\n",
    "print len(out)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###Call the slope functions and add them to the dataframe."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 230,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def make_func_caller_find_lag_integral(df_P, min_time, max_time, interval, column):\n",
    "    i = min_time\n",
    "    while i <= max_time:    \n",
    "        df_P[str(column) + '_int' + '_lag_' + str(i)] = find_lag_integral(df_P, i, column)      \n",
    "        i += interval\n",
    "    return df_P  \n",
    "\n",
    "def make_func_caller_find_lead_integral(df_P, min_time, max_time, interval, column):\n",
    "    i = min_time\n",
    "    while i <= max_time:    \n",
    "        df_P[str(column) + '_int' + '_lag_' + str(i)] = find_lead_integral(df_P, i, column)      \n",
    "        i += interval\n",
    "    return df_P \n",
    "\n",
    "def make_func_caller_sliding_integral_lag(df_P, max_end_min_before, min_end_min_before, frequency, interval_size, column):\n",
    "    i = min_end_min_before\n",
    "    while i <= max_end_min_before:\n",
    "        start = i + interval_size\n",
    "        df_P[str(column) + '_int' + '_slide_' + str(start) + '_to_' + str(i) + '_lag'] = sliding_integral_lag(df_P, start, i, column)      \n",
    "        i += frequency\n",
    "    return df_P \n",
    "\n",
    "def make_func_caller_sliding_integral_lead(df_P, start_min_after, end_min_after, frequency, interval_size, column):\n",
    "    i = min_end_min_before\n",
    "    while i <= max_end_min_before:\n",
    "        start = i + interval_size\n",
    "        df_P[str(column) + '_int' + '_slide_' + str(start) + '_to_' + str(i) + '_lead'] = sliding_integral_lead(df_P, start, i, column)      \n",
    "        i += frequency\n",
    "    return df_P \n",
    "\n",
    "def make_func_caller_find_lag_slope(df_P, min_time, max_time, interval, column):\n",
    "    i = min_time\n",
    "    while i <= max_time:    \n",
    "        df_P[str(column) + '_slope' + '_lag_' + str(i)] = find_lag_slope(df_P, i, column)      \n",
    "        i += interval\n",
    "    return df_P \n",
    "\n",
    "def make_func_caller_find_lead_slope(df_P, min_time, max_time, interval, column):\n",
    "    i = min_time\n",
    "    while i <= max_time:    \n",
    "        df_P[str(column) + '_slope' + '_lead_' + str(i)] = find_lead_slope(df_P, i, column)      \n",
    "        i += interval\n",
    "    return df_P \n",
    "\n",
    "def make_func_caller_find_sliding_slope(df_P, start_bef_or_aft_point, end_bef_or_aft_point, size, column):\n",
    "    i = size\n",
    "    while i <= size:    \n",
    "        df_P[str(column) + '_slope' + '_slide_' + str(i)] = find_sliding_slope(df_P, start_bef_or_aft_point, end_bef_or_aft_point, i, column)      \n",
    "        i += size\n",
    "    return df_P"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 231,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#call the lag int function for o3, temp, and rh\n",
    "make_func_caller_find_lag_integral(df_P, 5, 120, 15, 'e2v03')\n",
    "make_func_caller_find_lag_integral(df_P, 5, 120, 15, 'Temp')\n",
    "make_func_caller_find_lag_integral(df_P, 5, 120, 15, 'Rh')\n",
    "\n",
    "#call the lead int for o3, temp, and rh\n",
    "make_func_caller_find_lead_integral(df_P, 5, 120, 15, 'e2v03')\n",
    "make_func_caller_find_lead_integral(df_P, 5, 120, 15, 'Temp')\n",
    "make_func_caller_find_lead_integral(df_P, 5, 120, 15, 'Rh')\n",
    "\n",
    "#call the lag sliding integral function\n",
    "# inputs- (df_P, max_end_min_before, min_end_min_before, frequency, interval_size, column)\n",
    "make_func_caller_sliding_integral_lag(df_P, 15, 0, 5, 5, 'e2v03')\n",
    "make_func_caller_sliding_integral_lag(df_P, 15, 0, 5, 10, 'e2v03')\n",
    "make_func_caller_sliding_integral_lag(df_P, 15, 0, 5, 15, 'e2v03')\n",
    "\n",
    "make_func_caller_sliding_integral_lag(df_P, 15, 0, 5, 5, 'Temp')\n",
    "make_func_caller_sliding_integral_lag(df_P, 15, 0, 5, 10, 'Temp')\n",
    "make_func_caller_sliding_integral_lag(df_P, 15, 0, 5, 15, 'Temp')\n",
    "\n",
    "make_func_caller_sliding_integral_lag(df_P, 15, 0, 5, 5, 'Rh')\n",
    "make_func_caller_sliding_integral_lag(df_P, 15, 0, 5, 10, 'Rh')\n",
    "make_func_caller_sliding_integral_lag(df_P, 15, 0, 5, 15, 'Rh')\n",
    "\n",
    "#call the lag slope for o3, temp, and rh\n",
    "make_func_caller_find_lag_slope(df_P, 5, 120, 15, 'e2v03')\n",
    "make_func_caller_find_lag_slope(df_P, 5, 120, 15, 'Temp')\n",
    "make_func_caller_find_lag_slope(df_P, 5, 120, 15, 'Rh')\n",
    "\n",
    "#call the lead slope for o3, temp, and rh\n",
    "make_func_caller_find_lead_slope(df_P,5, 120, 15, 'e2v03')\n",
    "make_func_caller_find_lead_slope(df_P, 5, 120, 15, 'Temp')\n",
    "make_func_caller_find_lead_slope(df_P, 5, 120, 15, 'Rh')\n",
    "\n",
    "features = list(df_P.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 232,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['O3_ppb',\n",
       " 'UnixTime',\n",
       " 'e2v03',\n",
       " 'Temp',\n",
       " 'Rh',\n",
       " 'Zenith Angle [degrees]',\n",
       " 'days from start',\n",
       " 'e2v03_int_lag_5',\n",
       " 'e2v03_int_lag_20',\n",
       " 'e2v03_int_lag_35',\n",
       " 'e2v03_int_lag_50',\n",
       " 'e2v03_int_lag_65',\n",
       " 'e2v03_int_lag_80',\n",
       " 'e2v03_int_lag_95',\n",
       " 'e2v03_int_lag_110',\n",
       " 'Temp_int_lag_5',\n",
       " 'Temp_int_lag_20',\n",
       " 'Temp_int_lag_35',\n",
       " 'Temp_int_lag_50',\n",
       " 'Temp_int_lag_65',\n",
       " 'Temp_int_lag_80',\n",
       " 'Temp_int_lag_95',\n",
       " 'Temp_int_lag_110',\n",
       " 'Rh_int_lag_5',\n",
       " 'Rh_int_lag_20',\n",
       " 'Rh_int_lag_35',\n",
       " 'Rh_int_lag_50',\n",
       " 'Rh_int_lag_65',\n",
       " 'Rh_int_lag_80',\n",
       " 'Rh_int_lag_95',\n",
       " 'Rh_int_lag_110',\n",
       " 'e2v03_int_slide_5_to_0_before',\n",
       " 'e2v03_int_slide_10_to_5_before',\n",
       " 'e2v03_int_slide_15_to_10_before',\n",
       " 'e2v03_int_slide_20_to_15_before',\n",
       " 'e2v03_int_slide_10_to_0_before',\n",
       " 'e2v03_int_slide_15_to_5_before',\n",
       " 'e2v03_int_slide_20_to_10_before',\n",
       " 'e2v03_int_slide_25_to_15_before',\n",
       " 'e2v03_int_slide_15_to_0_before',\n",
       " 'e2v03_int_slide_20_to_5_before',\n",
       " 'e2v03_int_slide_25_to_10_before',\n",
       " 'e2v03_int_slide_30_to_15_before',\n",
       " 'Temp_int_slide_5_to_0_before',\n",
       " 'Temp_int_slide_10_to_5_before',\n",
       " 'Temp_int_slide_15_to_10_before',\n",
       " 'Temp_int_slide_20_to_15_before',\n",
       " 'Temp_int_slide_10_to_0_before',\n",
       " 'Temp_int_slide_15_to_5_before',\n",
       " 'Temp_int_slide_20_to_10_before',\n",
       " 'Temp_int_slide_25_to_15_before',\n",
       " 'Temp_int_slide_15_to_0_before',\n",
       " 'Temp_int_slide_20_to_5_before',\n",
       " 'Temp_int_slide_25_to_10_before',\n",
       " 'Temp_int_slide_30_to_15_before',\n",
       " 'Rh_int_slide_5_to_0_before',\n",
       " 'Rh_int_slide_10_to_5_before',\n",
       " 'Rh_int_slide_15_to_10_before',\n",
       " 'Rh_int_slide_20_to_15_before',\n",
       " 'Rh_int_slide_10_to_0_before',\n",
       " 'Rh_int_slide_15_to_5_before',\n",
       " 'Rh_int_slide_20_to_10_before',\n",
       " 'Rh_int_slide_25_to_15_before',\n",
       " 'Rh_int_slide_15_to_0_before',\n",
       " 'Rh_int_slide_20_to_5_before',\n",
       " 'Rh_int_slide_25_to_10_before',\n",
       " 'Rh_int_slide_30_to_15_before',\n",
       " 'diff',\n",
       " 'e2v03_slope_lag_5',\n",
       " 'e2v03_slope_lag_20',\n",
       " 'e2v03_slope_lag_35',\n",
       " 'e2v03_slope_lag_50',\n",
       " 'e2v03_slope_lag_65',\n",
       " 'e2v03_slope_lag_80',\n",
       " 'e2v03_slope_lag_95',\n",
       " 'e2v03_slope_lag_110',\n",
       " 'Temp_slope_lag_5',\n",
       " 'Temp_slope_lag_20',\n",
       " 'Temp_slope_lag_35',\n",
       " 'Temp_slope_lag_50',\n",
       " 'Temp_slope_lag_65',\n",
       " 'Temp_slope_lag_80',\n",
       " 'Temp_slope_lag_95',\n",
       " 'Temp_slope_lag_110',\n",
       " 'Rh_slope_lag_5',\n",
       " 'Rh_slope_lag_20',\n",
       " 'Rh_slope_lag_35',\n",
       " 'Rh_slope_lag_50',\n",
       " 'Rh_slope_lag_65',\n",
       " 'Rh_slope_lag_80',\n",
       " 'Rh_slope_lag_95',\n",
       " 'Rh_slope_lag_110',\n",
       " 'e2v03_slope_lead_5',\n",
       " 'e2v03_slope_lead_20',\n",
       " 'e2v03_slope_lead_35',\n",
       " 'e2v03_slope_lead_50',\n",
       " 'e2v03_slope_lead_65',\n",
       " 'e2v03_slope_lead_80',\n",
       " 'e2v03_slope_lead_95',\n",
       " 'e2v03_slope_lead_110',\n",
       " 'Temp_slope_lead_5',\n",
       " 'Temp_slope_lead_20',\n",
       " 'Temp_slope_lead_35',\n",
       " 'Temp_slope_lead_50',\n",
       " 'Temp_slope_lead_65',\n",
       " 'Temp_slope_lead_80',\n",
       " 'Temp_slope_lead_95',\n",
       " 'Temp_slope_lead_110',\n",
       " 'Rh_slope_lead_5',\n",
       " 'Rh_slope_lead_20',\n",
       " 'Rh_slope_lead_35',\n",
       " 'Rh_slope_lead_50',\n",
       " 'Rh_slope_lead_65',\n",
       " 'Rh_slope_lead_80',\n",
       " 'Rh_slope_lead_95',\n",
       " 'Rh_slope_lead_110']"
      ]
     },
     "execution_count": 232,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 233,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                       O3_ppb    UnixTime      e2v03       Temp         Rh  \\\n",
      "DATE (MM/DD/YYYY)_MST                                                        \n",
      "7/10/14 22:25              57  1405031127  89.285714  43.900000  11.514286   \n",
      "7/10/14 22:26              56  1405031188  88.000000  43.900000  11.485714   \n",
      "7/10/14 22:27              52  1405031250  92.428571  43.900000  11.600000   \n",
      "7/10/14 22:28              57  1405031311  89.714286  43.928571  11.585714   \n",
      "7/10/14 22:29              49  1405031373  91.285714  43.985714  11.742857   \n",
      "\n",
      "                       Zenith Angle [degrees]  days from start  \\\n",
      "DATE (MM/DD/YYYY)_MST                                            \n",
      "7/10/14 22:25                       113.79576                0   \n",
      "7/10/14 22:26                       113.87865                0   \n",
      "7/10/14 22:27                       113.96083                0   \n",
      "7/10/14 22:28                       114.04229                0   \n",
      "7/10/14 22:29                       114.12302                0   \n",
      "\n",
      "                      e2v03_int_lag_5 e2v03_int_lag_20 e2v03_int_lag_35  \\\n",
      "DATE (MM/DD/YYYY)_MST                                                     \n",
      "7/10/14 22:25                360.4286         1775.024         3178.524   \n",
      "7/10/14 22:26                368.0119         1779.095         3189.881   \n",
      "7/10/14 22:27                377.4524         1780.667          3197.31   \n",
      "7/10/14 22:28                384.0238         1779.881         3200.774   \n",
      "7/10/14 22:29                389.0952         1779.167         3204.381   \n",
      "\n",
      "                             ...        Temp_slope_lead_95  \\\n",
      "DATE (MM/DD/YYYY)_MST        ...                             \n",
      "7/10/14 22:25                ...               -0.05654135   \n",
      "7/10/14 22:26                ...               -0.05774436   \n",
      "7/10/14 22:27                ...               -0.05789474   \n",
      "7/10/14 22:28                ...               -0.05789474   \n",
      "7/10/14 22:29                ...               -0.05889724   \n",
      "\n",
      "                      Temp_slope_lead_110 Rh_slope_lead_5 Rh_slope_lead_20  \\\n",
      "DATE (MM/DD/YYYY)_MST                                                        \n",
      "7/10/14 22:25                 -0.05155844            0.04       0.05357143   \n",
      "7/10/14 22:26                 -0.05181818      0.08047619       0.07785714   \n",
      "7/10/14 22:27                 -0.05233766      0.05142857       0.09714286   \n",
      "7/10/14 22:28                 -0.05257576               0       0.09571429   \n",
      "7/10/14 22:29                 -0.05285714     0.008571428       0.09285714   \n",
      "\n",
      "                      Rh_slope_lead_35 Rh_slope_lead_50 Rh_slope_lead_65  \\\n",
      "DATE (MM/DD/YYYY)_MST                                                      \n",
      "7/10/14 22:25                0.1102041       0.09514286       0.07648352   \n",
      "7/10/14 22:26                0.1155102       0.09671429       0.07736264   \n",
      "7/10/14 22:27                     0.12            0.098       0.07736264   \n",
      "7/10/14 22:28                     0.12            0.096       0.07538462   \n",
      "7/10/14 22:29                0.1232653       0.09657143        0.0756044   \n",
      "\n",
      "                      Rh_slope_lead_80 Rh_slope_lead_95 Rh_slope_lead_110  \n",
      "DATE (MM/DD/YYYY)_MST                                                      \n",
      "7/10/14 22:25               0.06696429       0.06691729        0.06324675  \n",
      "7/10/14 22:26                  0.06875       0.06736842        0.06350649  \n",
      "7/10/14 22:27               0.07660714       0.06902256        0.06376623  \n",
      "7/10/14 22:28                    0.075       0.06766917        0.06272727  \n",
      "7/10/14 22:29                0.0753869       0.06786967        0.06285714  \n",
      "\n",
      "[5 rows x 116 columns]\n"
     ]
    }
   ],
   "source": [
    "#Delete the first and last 115 rows of the dataframe to remove all NaNs.\n",
    "df_P = df_P.ix[120:len(df_P['e2v03'])-120]\n",
    "print df_P.ix[:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 234,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#df_P.drop(df_P.columns[[9]], axis=1, inplace=True)\n",
    "#print df_P[:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 235,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                       O3_ppb    UnixTime      e2v03       Temp         Rh  \\\n",
      "DATE (MM/DD/YYYY)_MST                                                        \n",
      "7/10/14 22:25              57  1405031127  89.285714  43.900000  11.514286   \n",
      "7/10/14 22:26              56  1405031188  88.000000  43.900000  11.485714   \n",
      "7/10/14 22:27              52  1405031250  92.428571  43.900000  11.600000   \n",
      "7/10/14 22:28              57  1405031311  89.714286  43.928571  11.585714   \n",
      "7/10/14 22:29              49  1405031373  91.285714  43.985714  11.742857   \n",
      "\n",
      "                       Zenith Angle [degrees]  days from start  \\\n",
      "DATE (MM/DD/YYYY)_MST                                            \n",
      "7/10/14 22:25                       113.79576                0   \n",
      "7/10/14 22:26                       113.87865                0   \n",
      "7/10/14 22:27                       113.96083                0   \n",
      "7/10/14 22:28                       114.04229                0   \n",
      "7/10/14 22:29                       114.12302                0   \n",
      "\n",
      "                      e2v03_int_lag_5 e2v03_int_lag_20 e2v03_int_lag_35  \\\n",
      "DATE (MM/DD/YYYY)_MST                                                     \n",
      "7/10/14 22:25                360.4286         1775.024         3178.524   \n",
      "7/10/14 22:26                368.0119         1779.095         3189.881   \n",
      "7/10/14 22:27                377.4524         1780.667          3197.31   \n",
      "7/10/14 22:28                384.0238         1779.881         3200.774   \n",
      "7/10/14 22:29                389.0952         1779.167         3204.381   \n",
      "\n",
      "                                ...           03_mult_rh_cu ln_03_mult_rh  \\\n",
      "DATE (MM/DD/YYYY)_MST           ...                                         \n",
      "7/10/14 22:25                   ...            1.086568e+09      6.935430   \n",
      "7/10/14 22:26                   ...            1.032576e+09      6.918441   \n",
      "7/10/14 22:27                   ...            1.232516e+09      6.977441   \n",
      "7/10/14 22:28                   ...            1.122931e+09      6.946403   \n",
      "7/10/14 22:29                   ...            1.231770e+09      6.977239   \n",
      "\n",
      "                      temp_mult_rh temp_mult_rh_sq temp_mult_rh_cu  \\\n",
      "DATE (MM/DD/YYYY)_MST                                                \n",
      "7/10/14 22:25           505.477143   255507.141761    1.291530e+08   \n",
      "7/10/14 22:26           504.222857   254240.689855    1.281940e+08   \n",
      "7/10/14 22:27           509.240000   259325.377600    1.320589e+08   \n",
      "7/10/14 22:28           508.943878   259023.870705    1.318286e+08   \n",
      "7/10/14 22:29           516.517959   266790.802081    1.378022e+08   \n",
      "\n",
      "                      ln_temp_mult_rh 03_mult_rh_&_temp 03_mult_rh_&_temp_sq  \\\n",
      "DATE (MM/DD/YYYY)_MST                                                          \n",
      "7/10/14 22:25                6.225503      45131.887740         2.036887e+09   \n",
      "7/10/14 22:26                6.223018      44371.611445         1.968840e+09   \n",
      "7/10/14 22:27                6.232919      47068.325715         2.215427e+09   \n",
      "7/10/14 22:28                6.232338      45659.536459         2.084793e+09   \n",
      "7/10/14 22:29                6.247110      47150.710841         2.223190e+09   \n",
      "\n",
      "                      03_mult_rh_&_temp_cu ln_03_mult_rh_&_temp_cu  \n",
      "DATE (MM/DD/YYYY)_MST                                               \n",
      "7/10/14 22:25                 9.192857e+13               32.152033  \n",
      "7/10/14 22:26                 8.736060e+13               32.101065  \n",
      "7/10/14 22:27                 1.042765e+14               32.278067  \n",
      "7/10/14 22:28                 9.519069e+13               32.186903  \n",
      "7/10/14 22:29                 1.048250e+14               32.283313  \n",
      "\n",
      "[5 rows x 144 columns]\n"
     ]
    }
   ],
   "source": [
    "#ozone terms\n",
    "df_P['O3_sqrt'] = np.sqrt(df_P['e2v03'].astype(float))\n",
    "df_P['O3_sq'] = df_P['e2v03']**2\n",
    "df_P['O3_cu'] = df_P['e2v03']**3\n",
    "df_P['ln_O3'] = np.log(df_P['e2v03'])\n",
    "\n",
    "#temp terms\n",
    "df_P['temp_sqrt'] = np.sqrt(df_P['Temp'].astype(float))\n",
    "df_P['temp_sq'] = df_P['Temp']**2\n",
    "df_P['temp_cu'] = df_P['Temp']**3\n",
    "df_P['ln_temp'] = np.log(df_P['Temp'])\n",
    "\n",
    "\n",
    "#rh terms\n",
    "df_P['rh_sqrt'] = np.sqrt(df_P['Rh'].astype(float))\n",
    "df_P['rh_sq'] = df_P['Rh']**2\n",
    "df_P['rh_cu'] = df_P['Rh']**3\n",
    "df_P['ln_rh'] = np.log(df_P['Rh'])\n",
    "\n",
    "\n",
    "#ozone/temp interactions\n",
    "df_P['03_mult_temp'] = df_P['e2v03']*df_P['Temp']\n",
    "df_P['03_mult_temp_sq'] = (df_P['e2v03']*df_P['Temp'])**2\n",
    "df_P['03_mult_temp_cu'] = (df_P['e2v03']*df_P['Temp'])**3\n",
    "df_P['ln_03_mult_temp'] = np.log(df_P['03_mult_temp'])\n",
    "\n",
    "\n",
    "#ozone/rh interactions\n",
    "df_P['03_mult_rh'] = df_P['e2v03']*df_P['Rh']\n",
    "df_P['03_mult_rh_sq'] = (df_P['e2v03']*df_P['Rh'])**2\n",
    "df_P['03_mult_rh_cu'] = (df_P['e2v03']*df_P['Rh'])**3\n",
    "df_P['ln_03_mult_rh'] = np.log(df_P['03_mult_rh'])\n",
    "\n",
    "#temp/rh interactions\n",
    "df_P['temp_mult_rh'] = df_P['Temp']*df_P['Rh']\n",
    "df_P['temp_mult_rh_sq'] = (df_P['Temp']*df_P['Rh'])**2\n",
    "df_P['temp_mult_rh_cu'] = (df_P['Temp']*df_P['Rh'])**3\n",
    "df_P['ln_temp_mult_rh'] = np.log(df_P['temp_mult_rh'])\n",
    "\n",
    "\n",
    "#ozone/rh/temp interactions\n",
    "df_P['03_mult_rh_&_temp'] = df_P['e2v03']*df_P['Rh']*df_P['Temp']\n",
    "df_P['03_mult_rh_&_temp_sq'] = (df_P['e2v03']*df_P['Rh']*df_P['Temp'])**2\n",
    "df_P['03_mult_rh_&_temp_cu'] = (df_P['e2v03']*df_P['Rh']*df_P['Temp'])**3\n",
    "df_P['ln_03_mult_rh_&_temp_cu'] = np.log(df_P['03_mult_rh_&_temp_cu'])\n",
    "\n",
    "print df_P[:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 236,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                       O3_ppb    UnixTime       e2v03       Temp         Rh  \\\n",
      "DATE (MM/DD/YYYY)_MST                                                         \n",
      "7/10/14 22:30              33  1405031430  101.166667  43.966667  11.916667   \n",
      "7/10/14 22:31              48  1405031487   98.142857  43.942857  11.742857   \n",
      "7/10/14 22:32              51  1405031548   97.142857  43.928571  11.600000   \n",
      "7/10/14 22:33              47  1405031610   94.000000  43.942857  11.628571   \n",
      "7/10/14 22:34              41  1405031671   97.714286  43.914286  11.642857   \n",
      "\n",
      "                       Zenith Angle [degrees]  days from start  \\\n",
      "DATE (MM/DD/YYYY)_MST                                            \n",
      "7/10/14 22:30                       114.20303                0   \n",
      "7/10/14 22:31                       114.28231                0   \n",
      "7/10/14 22:32                       114.36086                0   \n",
      "7/10/14 22:33                       114.43868                0   \n",
      "7/10/14 22:34                       114.51576                0   \n",
      "\n",
      "                      e2v03_int_lag_5 e2v03_int_lag_20 e2v03_int_lag_35  \\\n",
      "DATE (MM/DD/YYYY)_MST                                                     \n",
      "7/10/14 22:30                388.7262         1773.631         3202.869   \n",
      "7/10/14 22:31                386.9286         1765.524         3198.571   \n",
      "7/10/14 22:32                385.2857         1760.738         3197.143   \n",
      "7/10/14 22:33                383.5714         1758.952         3198.714   \n",
      "7/10/14 22:34                381.1429         1755.881         3201.714   \n",
      "\n",
      "                                ...           03_mult_rh_cu ln_03_mult_rh  \\\n",
      "DATE (MM/DD/YYYY)_MST           ...                                         \n",
      "7/10/14 22:30                   ...            1.752172e+09      7.094707   \n",
      "7/10/14 22:31                   ...            1.530726e+09      7.049669   \n",
      "7/10/14 22:32                   ...            1.430891e+09      7.027188   \n",
      "7/10/14 22:33                   ...            1.306059e+09      6.996760   \n",
      "7/10/14 22:34                   ...            1.472492e+09      7.036741   \n",
      "\n",
      "                      temp_mult_rh temp_mult_rh_sq temp_mult_rh_cu  \\\n",
      "DATE (MM/DD/YYYY)_MST                                                \n",
      "7/10/14 22:30           523.936111   274509.048721    1.438252e+08   \n",
      "7/10/14 22:31           516.014694   266271.164133    1.373998e+08   \n",
      "7/10/14 22:32           509.571429   259663.040833    1.323169e+08   \n",
      "7/10/14 22:33           510.992653   261113.491513    1.334271e+08   \n",
      "7/10/14 22:34           511.287755   261415.168338    1.336584e+08   \n",
      "\n",
      "                      ln_temp_mult_rh 03_mult_rh_&_temp 03_mult_rh_&_temp_sq  \\\n",
      "DATE (MM/DD/YYYY)_MST                                                          \n",
      "7/10/14 22:30                6.261370      53004.869944         2.809516e+09   \n",
      "7/10/14 22:31                6.246135      50643.156368         2.564729e+09   \n",
      "7/10/14 22:32                6.233570      49501.224490         2.450371e+09   \n",
      "7/10/14 22:33                6.236355      48033.309391         2.307199e+09   \n",
      "7/10/14 22:34                6.236933      49960.117765         2.496013e+09   \n",
      "\n",
      "                      03_mult_rh_&_temp_cu ln_03_mult_rh_&_temp_cu  \n",
      "DATE (MM/DD/YYYY)_MST                                               \n",
      "7/10/14 22:30                 1.489180e+14               32.634417  \n",
      "7/10/14 22:31                 1.298860e+14               32.497678  \n",
      "7/10/14 22:32                 1.212964e+14               32.429258  \n",
      "7/10/14 22:33                 1.108224e+14               32.338950  \n",
      "7/10/14 22:34                 1.247011e+14               32.456941  \n",
      "\n",
      "[5 rows x 144 columns]\n"
     ]
    }
   ],
   "source": [
    "#Delete the first and last 115 rows of the dataframe to remove all NaNs.\n",
    "df_P = df_P.ix[5:len(df_P['e2v03'])-5]\n",
    "print df_P.ix[:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 237,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "df_P.to_csv(path_or_buf = 'data/D0_raw_features.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
